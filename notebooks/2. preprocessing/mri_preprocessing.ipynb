{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 20:52:49.232761: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-16 20:52:49.270290: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-16 20:52:49.962914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Input\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_mris_and_labels(mri_directory, csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    mris = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "\n",
    "    for filename in os.listdir(mri_directory):\n",
    "        if filename.endswith(\".nii\") or filename.endswith(\".nii.gz\"):\n",
    "            rsct_id = filename.split('_')[0].split('-')[1]  # Adjusted to match your filename format\n",
    "            img = nib.load(os.path.join(mri_directory, filename))\n",
    "            label = df.loc[df['record_id'] == rsct_id, 'surg_engel'].values[0]\n",
    "\n",
    "            mris.append(img)\n",
    "            labels.append(label)\n",
    "            ids.append(rsct_id)\n",
    "\n",
    "    return mris, labels, ids\n",
    "\n",
    "def create_model(input_shape):\n",
    "    \"\"\" Create a 3D CNN model. \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv3D(32, kernel_size=(3, 3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "mris, labels, ids = load_mris_and_labels('../../scripts/flirt_raw', '../../data/processed/label_df.csv')\n",
    "\n",
    "# Convert MRI data to numpy array\n",
    "mris_array = np.array([mri.get_fdata() for mri in mris])[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 20:53:21.303442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.331113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.331165: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.334928: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.335000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.335025: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.583580: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.583669: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.583679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-16 20:53:21.583720: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-16 20:53:21.583758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718535203.389619   34341 service.cc:145] XLA service 0x7fd02c005000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718535203.389676   34341 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-06-16 20:53:23.408548: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-16 20:53:23.541111: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3750 - loss: 31368.1797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718535206.931963   34341 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - accuracy: 0.4740 - loss: 27483.1543 - val_accuracy: 0.4167 - val_loss: 1482.7401\n",
      "Epoch 2/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6338 - loss: 912.0750 - val_accuracy: 0.5833 - val_loss: 356.7805\n",
      "Epoch 3/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9415 - loss: 28.9901 - val_accuracy: 0.5000 - val_loss: 161.9000\n",
      "Epoch 4/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.5237e-40 - val_accuracy: 0.6667 - val_loss: 59.9186\n",
      "Epoch 5/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.4013e-44 - val_accuracy: 0.8333 - val_loss: 48.7941\n",
      "Epoch 6/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 50.5259\n",
      "Epoch 7/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 51.0610\n",
      "Epoch 8/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 51.2224\n",
      "Epoch 9/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 51.2716\n",
      "Epoch 10/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 51.2857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fd136be4a30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data\n",
    "X = mris_array[:60]\n",
    "y = np.array(labels)[:60]\n",
    "\n",
    "# Convert labels to binary (1 if label is 1, else 0)\n",
    "y = np.where(y == 1, 1, 0)\n",
    "\n",
    "# Verify labels for the subset\n",
    "#print(f'Labels for the first 20 samples: {y}')\n",
    "\n",
    "# Define input shape for the model\n",
    "input_shape = X.shape[1:]\n",
    "\n",
    "# Create the model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure the input data shape is correct\n",
    "#print(f'X_train shape: {X_train.shape}')  # This should print (number of samples, 91, 109, 91, 1)\n",
    "#print(f'y_train shape: {y_train.shape}')  # This should print (number of samples,)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "model.save('my_model.h5')\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the file\n",
    "#loaded_model = load_model('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 20:56:17.588645: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.23GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-16 20:56:17.590547: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.3 = (f32[12,32,89,107,89]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[12,1,91,109,91]{4,3,2,1,0} %bitcast.158, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.5, f32[32]{0} %arg2.3), window={size=3x3x3}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"functional_1_1/conv3d_1/convolution\" source_file=\"/home/amaury/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1318609408 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2024-06-16 20:56:17.590631: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.3 = (f32[12,32,89,107,89]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[12,1,91,109,91]{4,3,2,1,0} %bitcast.158, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.5, f32[32]{0} %arg2.3), window={size=3x3x3}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"functional_1_1/conv3d_1/convolution\" source_file=\"/home/amaury/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1318609408 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_33984/2224580921.py\", line 2, in <module>\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 504, in predict\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 204, in one_step_on_data_distributed\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.3 = (f32[12,32,89,107,89]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[12,1,91,109,91]{4,3,2,1,0} %bitcast.158, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.5, f32[32]{0} %arg2.3), window={size=3x3x3}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"functional_1_1/conv3d_1/convolution\" source_file=\"/home/amaury/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1318609408 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_3807]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Since the output is a probability, convert it to binary labels (0 or 1)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m (predictions \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_33984/2224580921.py\", line 2, in <module>\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 504, in predict\n\n  File \"/home/amaury/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 204, in one_step_on_data_distributed\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.3 = (f32[12,32,89,107,89]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[12,1,91,109,91]{4,3,2,1,0} %bitcast.158, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.5, f32[32]{0} %arg2.3), window={size=3x3x3}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"functional_1_1/conv3d_1/convolution\" source_file=\"/home/amaury/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1318609408 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_3807]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Since the output is a probability, convert it to binary labels (0 or 1)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Select an example to visualize (e.g., the first example)\n",
    "example_index = 0\n",
    "\n",
    "# Get the MRI, true label, and prediction\n",
    "mri_example = X_test[example_index]\n",
    "true_label = y_test[example_index]\n",
    "predicted_label = predicted_labels[example_index][0]\n",
    "\n",
    "# Print the true label and prediction\n",
    "print(f'True Label: {true_label}, Prediction: {predicted_label}')\n",
    "\n",
    "# Plot the MRI slices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Select three slices to visualize (middle slices of each dimension)\n",
    "slices = [mri_example[mri_example.shape[0] // 2, :, :, 0],\n",
    "          mri_example[:, mri_example.shape[1] // 2, :, 0],\n",
    "          mri_example[:, :, mri_example.shape[2] // 2, 0]]\n",
    "\n",
    "for i, slice in enumerate(slices):\n",
    "    axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
    "    axes[i].set_title(f'Slice {i+1}')\n",
    "\n",
    "plt.suptitle(f'True Label: {true_label}, Prediction: {predicted_label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "def load_mris_and_labels(mri_directory, csv_file):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    mris = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "\n",
    "    for filename in os.listdir(mri_directory):\n",
    "        if filename.endswith(\".nii\") or filename.endswith(\".nii.gz\"):\n",
    "            # Extract the RSCT id from the filename\n",
    "            rsct_id = filename.split('_')[0].split('-')[1]  # Adjusted to match your filename format\n",
    "\n",
    "            # Load the MRI file\n",
    "            img = nib.load(os.path.join(mri_directory, filename))\n",
    "\n",
    "            # Find the corresponding label\n",
    "            label = df.loc[df['record_id'] == rsct_id, 'surg_engel'].values[0]\n",
    "\n",
    "            mris.append(img)\n",
    "            labels.append(label)\n",
    "            ids.append(rsct_id)\n",
    "\n",
    "    return mris, labels, ids\n",
    "\n",
    "# Usage\n",
    "mris, labels, ids = load_mris_and_labels('../../scripts/flirt_raw', '../../data/processed/label_df.csv')\n",
    "\n",
    "# Print the shape, ID, and surg_engel for the first 10 MRIs\n",
    "for i in range(10):\n",
    "    print(f'ID: {ids[i]}, Shape: {mris[i].shape}, surg_engel: {labels[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def find_latest_t1w_scan(base_path):\n",
    "    participant_scans = {}\n",
    "    for item in os.listdir(base_path):\n",
    "        # Check if the folder name starts with 'sub-', indicating a participant folder\n",
    "        if item.startswith('sub-'):\n",
    "            participant_path = os.path.join(base_path, item)\n",
    "            # Strip 'sub-' prefix to use as the dictionary key\n",
    "            participant_id = item[4:]  # Removes the first four characters 'sub-'\n",
    "            latest_date = None\n",
    "            latest_file = None\n",
    "\n",
    "            # Check each session folder within the participant directory\n",
    "            for session_folder in os.listdir(participant_path):\n",
    "                if session_folder.startswith('ses-'):\n",
    "                    session_date = session_folder.split('-')[1]  # Extract the date from the session folder name\n",
    "                    session_path = os.path.join(participant_path, session_folder)\n",
    "                    anat_path = os.path.join(session_path, 'anat')  # 'anat' folder inside the session folder\n",
    "\n",
    "                    if os.path.exists(anat_path) and os.path.isdir(anat_path):\n",
    "                        # Iterate over all .nii files in the 'anat' directory\n",
    "                        for file in os.listdir(anat_path):\n",
    "                            if file.endswith('T1w.nii'):\n",
    "                                file_date = datetime.strptime(session_date, \"%Y%m%d\")\n",
    "                                # Update if this file's date is more recent\n",
    "                                if latest_date is None or file_date > latest_date:\n",
    "                                    latest_date = file_date\n",
    "                                    latest_file = os.path.join(anat_path, file)\n",
    "\n",
    "            if latest_file:\n",
    "                participant_scans[participant_id] = latest_file\n",
    "\n",
    "    return participant_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../../data/raw/resectMap_nifti_only_20240430'\n",
    "latest_scans = find_latest_t1w_scan(base_path)\n",
    "#latest_scans.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prediction data\n",
    "prediction_data = pd.read_csv('../../data/processed/label_df.csv', index_col=0)\n",
    "\n",
    "# Convert latest_scans dictionary to DataFrame\n",
    "scans_df = pd.DataFrame(list(latest_scans.items()), columns=['ParticipantID', 'ScanPath'])\n",
    "\n",
    "# Merge the dataframes\n",
    "prediction_data = prediction_data.rename(columns={\"record_id\" : \"ParticipantID\"})\n",
    "final_data = prediction_data.merge(scans_df, on='ParticipantID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('../../data/processed/MRI_file_path.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "def load_mri(path):\n",
    "    mri = nib.load(path)\n",
    "    return mri.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_mri(data):\n",
    "    # Normalize the data to [0, 1]\n",
    "    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = final_data.dropna(subset=['ScanPath']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in subset_df.iterrows():\n",
    "    mri_data = load_mri(row['ScanPath'])\n",
    "    print(f\"Participant ID: {row['ParticipantID']}, Shape: {mri_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem : MRIs with different shapes -> need resize\n",
    "if False:\n",
    "    X = []  # Image data\n",
    "    y = []  # Labels\n",
    "\n",
    "    # Remove participants without any T1w MRI scans\n",
    "    final_data = final_data.dropna(subset=['ScanPath'])\n",
    "\n",
    "    for _, row in subset_df.iterrows():\n",
    "        mri_data = load_mri(row['ScanPath'])\n",
    "        mri_data = preprocess_mri(mri_data)\n",
    "        X.append(mri_data)\n",
    "        y.append(row['surg_engel'])\n",
    "\n",
    "    X = np.array(X)  # Convert list to array for training\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def resize_mri(data, new_shape=(64, 64, 64)):\n",
    "    \"\"\" Resize the MRI to new_shape \"\"\"\n",
    "    # Calculate the zoom factors\n",
    "    zoom_factors = np.array(new_shape) / np.array(data.shape)\n",
    "    # Apply the zoom operation with bilinear interpolation\n",
    "    return zoom(data, zoom_factors, order=1)  # order=1 (bilinear) is often a good trade-off\n",
    "\n",
    "\n",
    "def preprocess_and_load_mris(df):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        mri_data = load_mri(row['ScanPath'])\n",
    "        mri_data = preprocess_mri(mri_data)\n",
    "        mri_data_resized = resize_mri(mri_data)\n",
    "        X.append(mri_data_resized)\n",
    "        y.append(row['surg_engel'])\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_and_load_mris(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "\n",
    "def create_model(input_shape):\n",
    "    \"\"\" Create a 3D CNN model. \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[..., np.newaxis]  # Add a channel dimension, assuming X doesn't already have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]\n",
    "model = create_model(input_shape)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(X.shape[1], X.shape[2], X.shape[3], 1)),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "class MRISequence(Sequence):\n",
    "    def __init__(self, df, batch_size):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.df.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X = []\n",
    "        y = []\n",
    "        for _, row in batch_x.iterrows():\n",
    "            mri_data = load_mri(row['ScanPath'])\n",
    "            mri_data = preprocess_mri(mri_data)\n",
    "            mri_data_resized = resize_mri(mri_data)\n",
    "            X.append(mri_data_resized)\n",
    "            y.append(row['Outcome'])\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "# Usage\n",
    "batch_size = 2  # You can adjust the batch size\n",
    "train_gen = MRISequence(df=subset_df, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "\n",
    "def create_model(input_shape):\n",
    "    # Create a Sequential model\n",
    "    model = Sequential([\n",
    "        Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Assuming your input shape from the preprocessed MRI data is known, e.g., (64, 64, 64, 1)\n",
    "input_shape = (64, 64, 64, 1)\n",
    "model = create_model(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_gen, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print system information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
